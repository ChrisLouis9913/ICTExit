{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/zSVxlvCOsXWO9YbSwdFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisLouis9913/ICTExit/blob/main/Reteston7thNov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HZmLjAEjlm9",
        "outputId": "b845c798-5dcd-4d25-bdc3-8f4d25c9f176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-727082838.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(med, inplace=True)\n",
            "/tmp/ipython-input-727082838.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(med, inplace=True)\n",
            "/tmp/ipython-input-727082838.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(med, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned columns: ['price_local', 'model', 'price_local', 'review_date']\n",
            "price_local    float64\n",
            "model          float64\n",
            "price_local    float64\n",
            "review_date    float64\n",
            "dtype: object\n",
            "price_local    0\n",
            "model          0\n",
            "price_local    0\n",
            "review_date    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-727082838.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(0, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/mobile_review.csv\")\n",
        "\n",
        "# Columns to clean: include 'price_local' if present and also any object columns that contain digits\n",
        "candidate_obj_cols = [c for c in df.select_dtypes(include=\"object\").columns\n",
        "                      if df[c].astype(str).str.contains(r\"\\d\", na=False).any()]\n",
        "cols_to_clean = [c for c in ([\"price_local\"] + candidate_obj_cols) if c in df.columns]\n",
        "\n",
        "def clean_numeric_series(s: pd.Series) -> pd.Series:\n",
        "    # convert to string, handle negatives in parentheses, strip whitespace\n",
        "    s2 = s.astype(str).str.strip()\n",
        "    s2 = s2.replace({\"nan\": \"\"})  # pandas may have 'nan' strings\n",
        "    s2 = s2.str.replace(r'^\\((.*)\\)$', r'-\\1', regex=True)  # (123) -> -123\n",
        "    # remove all characters except digits, dot and minus\n",
        "    s2 = s2.str.replace(r'[^0-9\\.\\-]', '', regex=True)\n",
        "    # empty strings -> NaN, then convert to numeric (coerce invalid)\n",
        "    s2 = s2.replace('', np.nan)\n",
        "    return pd.to_numeric(s2, errors=\"coerce\")\n",
        "\n",
        "# Clean each column and handle NaNs (fill with median or 0 if median is NaN)\n",
        "for col in cols_to_clean:\n",
        "    df[col] = clean_numeric_series(df[col])\n",
        "    med = df[col].median(skipna=True)\n",
        "    if np.isnan(med):\n",
        "        df[col].fillna(0, inplace=True)\n",
        "    else:\n",
        "        df[col].fillna(med, inplace=True)\n",
        "\n",
        "# Quick check\n",
        "print(\"Cleaned columns:\", cols_to_clean)\n",
        "print(df[cols_to_clean].dtypes)\n",
        "print(df[cols_to_clean].isna().sum())\n",
        "\n",
        "# df is ready for further use"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# determine feature columns (use existing cols_to_clean if available)\n",
        "if 'cols_to_clean' in globals():\n",
        "    feature_cols = [c for c in cols_to_clean if c in df.columns]\n",
        "else:\n",
        "    feature_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != \"Rating\"]\n",
        "\n",
        "if \"price_local\" not in df.columns:\n",
        "    raise KeyError(\"Column 'Rating' not found in dataframe\")\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[\"price_local\"].copy()\n",
        "\n",
        "# ensure no NaNs in features\n",
        "for c in X.columns:\n",
        "    if X[c].isna().any():\n",
        "        med = X[c].median(skipna=True)\n",
        "        X[c].fillna(med if not np.isnan(med) else 0, inplace=True)\n",
        "\n",
        "# split, scale, train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# print coefficients per feature\n",
        "for name, coef in zip(X.columns, model.coef_):\n",
        "    print(f\"{name}: {coef:.6f}\")\n",
        "print(\"Intercept:\", model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "RV6HRnr6qNkZ",
        "outputId": "cb2a1d37-8bd6-446c-9a57-88ce924fb93d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-289283269.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# ensure no NaNs in features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Create sentiment mapping dictionary\n",
        "sentiment_map = {\n",
        "    1: \"Positive\",\n",
        "    0: \"Neutral\",\n",
        "    -1: \"Negative\"\n",
        "}\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and preprocess text data\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove special characters and numbers\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        # Remove extra whitespace\n",
        "        text = ' '.join(text.split())\n",
        "        # Remove stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "        return text\n",
        "    return ''\n",
        "\n",
        "# Create Sentiment_Label column\n",
        "df['Review_Length'] = df['review_length'].map(sentiment_map)\n",
        "\n",
        "# Drop rows with missing review text\n",
        "df = df.dropna(subset=['Review_body'])\n",
        "\n",
        "# Clean the text\n",
        "df['cleaned_text'] = df['Review_body'].apply(clean_text)\n",
        "\n",
        "# Split features and target\n",
        "X = df['cleaned_text']\n",
        "y = df['Review_Length']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create and fit TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Example prediction\n",
        "def predict_sentiment(text):\n",
        "    cleaned = clean_text(text)\n",
        "    tfidf_vector = tfidf.transform([cleaned])\n",
        "    prediction = model.predict(tfidf_vector)\n",
        "    return prediction[0]\n",
        "\n",
        "# Test the model with a sample review\n",
        "sample_text = \"This product is amazing and works perfectly!\"\n",
        "print(f\"\\nSample text: {sample_text}\")\n",
        "print(f\"Predicted sentiment: {predict_sentiment(sample_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "yu8MGWggyQzZ",
        "outputId": "eecd4719-727b-4346-b667-3580a28ca781"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "['Review_body']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2839235755.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Drop rows with missing review text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Review_body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Clean the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ['Review_body']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Initialize and fit the tokenizer\n",
        "MAX_WORDS = 10000  # Maximum number of words to keep\n",
        "MAX_LEN = 100     # Maximum length of each sequence\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)\n",
        "\n",
        "# Convert labels to categorical\n",
        "label_dict = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
        "y_train_cat = to_categorical([label_dict[label] for label in y_train])\n",
        "y_test_cat = to_categorical([label_dict[label] for label in y_test])\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Embedding(MAX_WORDS, 100, input_length=MAX_LEN),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(32),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_pad,\n",
        "    y_train_cat,\n",
        "    batch_size=32,\n",
        "    epochs=5,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test_cat)\n",
        "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fIuMyEYy3ouG",
        "outputId": "8f72a441-9109-4bee-ab87-b81202d2e0c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1584233664.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Convert text to sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions with the trained model\n",
        "predictions = model.predict(X_test_pad)\n",
        "predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "reverse_label_dict = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "predicted_labels = [reverse_label_dict[i] for i in predicted_classes]\n",
        "actual_labels = [label for label in y_test]\n",
        "\n",
        "# Print classification report for deep learning model\n",
        "print(\"\\nDeep Learning Model Classification Report:\")\n",
        "print(classification_report(actual_labels, predicted_labels))\n",
        "\n",
        "# Function to predict sentiment using the deep learning model\n",
        "def predict_sentiment_dl(text):\n",
        "    # Preprocess the text\n",
        "    cleaned = clean_text(text)\n",
        "    # Convert to sequence\n",
        "    sequence = tokenizer.texts_to_sequences([cleaned])\n",
        "    # Pad sequence\n",
        "    padded = pad_sequences(sequence, maxlen=MAX_LEN)\n",
        "    # Make prediction\n",
        "    pred = model.predict(padded)\n",
        "    # Get predicted class\n",
        "    pred_class = pred.argmax(axis=1)[0]\n",
        "    return reverse_label_dict[pred_class]\n",
        "\n",
        "# Test the deep learning model with the same sample\n",
        "print(\"\\nDeep Learning Model Prediction:\")\n",
        "print(f\"Sample text: {sample_text}\")\n",
        "print(f\"Predicted sentiment: {predict_sentiment_dl(sample_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "aqzjZvKr498H",
        "outputId": "479b6486-f408-4a1e-f56a-44580f0182f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1777170062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Make predictions with the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Last question: I don't know ðŸ˜ž"
      ],
      "metadata": {
        "id": "T0PKI25D6QdY"
      }
    }
  ]
}